{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cudacheck] Is cuda available?  False\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json, csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from transformers import AutoTokenizer\n",
    "from elasticsearch_dsl import Document, Integer, Text, DenseVector\n",
    "from elasticsearch_dsl.connections import connections\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from dataclasses_json import dataclass_json\n",
    "from dacite import from_dict\n",
    "from nltk import tokenize\n",
    "from omegaconf import OmegaConf \n",
    "from pprint import pprint\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import src.data\n",
    "from src.data import load_metadata, find_paths, relative_file_path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../contrastive_mm2/') \n",
    "from gru_test2 import mmModule, Cfg\n",
    "from prepare_index_sentencelevel2 import read_metadata_subset\n",
    "\n",
    "# Load static configuration variables. \n",
    "config_path = \"./config.yaml\"\n",
    "conf = OmegaConf.load(config_path)\n",
    "print(\"[cudacheck] Is cuda available? \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TO ARGS\"\"\"\n",
    "model_path = \"E:\\msc_thesis\\code\\contrastive_mm2\\logs\\lisa_v2-simcse_loss_rnn_relu_768_2e-05_2022-05-17_06-58-44\"\n",
    "model_path = '/Users/casper/Documents/UvAmaster/b23456_thesis/msc_thesis/code/contrastive_mm2/logs/windows_gru2-clip_loss_gru_gelu_768_5e-05_2022-05-26_21-51-25'\n",
    "model_path = '/Users/casper/Documents/UvAmaster/b23456_thesis/msc_thesis/code/contrastive_mm2/logs/windows_gru2-clip_loss_followup'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transcripts_path = '/Users/casper/Documents/UvAmaster/b23456_thesis/msc_thesis/code/data/sp/podcasts-no-audio-13GB/podcasts-transcripts'\n",
    "# transcripts_path = 'E:/msc_thesis/code/data/sp/podcasts-no-audio-13GB/podcasts-transcripts'\n",
    "\n",
    "# Whether we create for the train or the tes split. \n",
    "traintest = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] metadata loaded  105360\n",
      "[main] topics_test loaded  50\n",
      "[main] topics_df_targets loaded for test set 9426\n",
      "[main] metadata_subset loaded  9426\n",
      "[main] Topic test set loaded:  3421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating output directory.\n",
    "save_name = os.path.split(model_path)[-1]\n",
    "save_path = os.path.join(conf.yamnet_topic_embed_path, save_name + \"_\" + traintest)\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Reading the metadata.\n",
    "metadata_testset, topics_df, topics_df_targets = read_metadata_subset(conf, traintest='test')\n",
    "\n",
    "# Remove duplicate rows\n",
    "metadata_testset = metadata_testset.drop_duplicates(subset=['episode_filename_prefix']).sort_values('episode_filename_prefix')\n",
    "print(\"[main] Topic test set loaded: \", len(metadata_testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load model] from  /Users/casper/Documents/UvAmaster/b23456_thesis/msc_thesis/code/contrastive_mm2/logs/windows_gru2-clip_loss_followup\n",
      "[Load model] weights loaded\n",
      "using config: ,  {'audio_dropout': 0.1, 'audio_encoder_input': 1024, 'audio_hidden_dim': 768, 'audio_layer_dim': 2, 'device': 'cuda', 'lr': 5e-05, 'mutual_embedding_dim': 768, 'text_dropout': 0.1, 'text_max_length': 32, 'text_model_name': 'distilbert-base-uncased', 'text_tokenizer': 'distilbert-base-uncased', 'weight_decay': 0.01, 'audio_activation': 'gelu', 'audio_proj_head': 'gru', 'batch_size': 128, 'cuda_number': '0', 'dev_dataset': 'sts', 'eval_every': 100, 'final_projection_dim': 768, 'fp16': False, 'load_checkpoint': False, 'load_checkpoint_path': './logs/load_test2/output/checkpoint.pth', 'load_model': False, 'load_model_path': './logs/load_test2/output/full_model_weights.pth', 'log_dir': './logs', 'loss_type': 'clip_loss', 'no_cuda': False, 'normalize': True, 'num_epochs': 10, 'pad_pack': True, 'save_checkpoint': True, 'save_model': True, 'scale': 20, 'scale_type': 'fixed', 'seed': 100, 'val_dataset': 'sp', 'test_dataset': 'sp', 'test_evalchange': False, 'text_activation': 'gelu', 'text_pooling': 'mean', 'text_proj_head': 'None', 'train_dataset': 'sp', 'use_lr': False, 'use_old_opt': False}\n",
      "\n",
      "\n",
      "\n",
      "[Load model] config loaded:  Cfg(batch_size=128, num_epochs=10, loss_type='clip_loss', lr=5e-05, device='cpu', audio_encoder_input=1024, audio_hidden_dim=768, audio_layer_dim=2, audio_activation='gelu', text_model_name='distilbert-base-uncased', text_tokenizer='distilbert-base-uncased', text_pooling='mean', text_max_length=32, text_proj_head='None', audio_proj_head='gru', text_activation='gelu', mutual_embedding_dim=768, final_projection_dim=768, audio_dropout=0.1, text_dropout=0.1, weight_decay=0.01, scale_type='fixed', scale=20, pad_pack=True, normalize=True, eval_every=100, print_every=1, log_name='logname', train_dataset='sp', val_dataset='sp', test_dataset='sp', seed=100, save_model=True, save_checkpoint=True, load_model_path='./logs/load_test2/output/full_model_weights.pth', load_model=False, load_checkpoint=False, load_checkpoint_path='./logs/load_test2/output/checkpoint.pth')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading the model.\n",
    "print(\"[Load model] from \", model_path)\n",
    "model_weights = os.path.join(model_path, \"output/full_model_weights.pth\")\n",
    "print(\"[Load model] weights loaded\")\n",
    "model_config_path = os.path.join(model_path, 'config.json')\n",
    "\n",
    "# Opening JSON file\n",
    "f = open(model_config_path)\n",
    "model_config = json.load(f)\n",
    "print(\"using config: , \", model_config)\n",
    "print(\"\\n\\n\")\n",
    "CFG = from_dict(data_class=Cfg, data=model_config)\n",
    "CFG.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# mutual_embed_dim = CFG.final_projection_dim\n",
    "print(\"[Load model] config loaded: \", CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transformer_multimodal] Configurations used: \n",
      " DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load model] model loaded:  /Users/casper/Documents/UvAmaster/b23456_thesis/msc_thesis/code/contrastive_mm2/logs/windows_gru2-clip_loss_followup/output/full_model_weights.pth\n",
      "tensor(0.0674)\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "full_model = mmModule(CFG)\n",
    "full_model.load_state_dict(torch.load(model_weights,  map_location=CFG.device))                      \n",
    "full_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.text_model_name)\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(CFG.text_tokenizer)\n",
    "print(\"[Load model] model loaded: \", model_weights)\n",
    "print(full_model.state_dict()['audio_model.0.seq_model.weight_ih_l1'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[MMloader] train dataset  sp\n",
      "[spDataset] init from directory  ../data/sp/yamnet/processed/ train\n",
      "[spDataset] found 1 h5py files\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/train/0_0_embeds.h5\n",
      "[MMloader] train dataset loaded, length:  19344\n",
      "[spDataset] init from directory  ../data/sp/yamnet/processed/ val\n",
      "[spDataset] found 1 h5py files\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/val/0_0_embeds.h5\n",
      "[spDataset] init from directory  ../data/sp/yamnet/processed/ test\n",
      "[spDataset] found 97 h5py files\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_N_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_R_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_1_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_G_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_M_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_2_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_C_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_6_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_J_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_V_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_K_embeds.h5\n",
      "[spdataset] loaded 10/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_A_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_4_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_T_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_H_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_7_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_F_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_P_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_L_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_9_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_Y_embeds.h5\n",
      "[spdataset] loaded 20/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_E_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_0_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_0_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_O_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_S_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_3_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_F_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_Z_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_L_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_7_embeds.h5\n",
      "[spdataset] loaded 30/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_B_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_K_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_A_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_W_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_5_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_J_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_6_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_U_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_I_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_8_embeds.h5\n",
      "[spdataset] loaded 40/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_G_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_Q_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_M_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_1_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_X_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_D_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_E_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_O_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_Y_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_0_embeds.h5\n",
      "[spdataset] loaded 50/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_L_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_P_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_3_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_9_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_H_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_T_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_B_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_A_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_4_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_V_embeds.h5\n",
      "[spdataset] loaded 60/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_J_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_5_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_I_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_C_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_G_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_2_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_8_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_R_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_D_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_N_embeds.h5\n",
      "[spdataset] loaded 70/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_1_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_D_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_N_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_X_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_2_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_8_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_M_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_Q_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_I_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_U_embeds.h5\n",
      "[spdataset] loaded 80/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_C_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_5_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_4_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_W_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_K_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_7_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_H_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_B_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_3_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_9_embeds.h5\n",
      "[spdataset] loaded 90/97\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_Z_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_F_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_P_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/0_S_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/2_E_embeds.h5\n",
      "[del] h5py_file:  ../data/sp/yamnet/processed/test/1_O_embeds.h5\n",
      "[MMloader] test dataset loaded, length:  525486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gru_test2 import MMloader\n",
    "\n",
    "# Create dataloader of test set\n",
    "data_loader = MMloader(CFG)\n",
    "train_loader = data_loader.train_loader\n",
    "val_loader = data_loader.val_loader\n",
    "test_loader = data_loader.test_loader # Not used!\n",
    "\n",
    "# TODO: move this into __init__ of dataloader\n",
    "data_loader.test_dataset.tokenizer = tokenizer\n",
    "data_loader.test_dataset.text_max_length = CFG.text_max_length\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4105\n",
      "step 0/4105\n",
      "step 1/4105\n",
      "step 2/4105\n",
      "step 3/4105\n",
      "step 4/4105\n",
      "step 5/4105\n",
      "step 6/4105\n",
      "step 7/4105\n",
      "step 8/4105\n",
      "step 9/4105\n",
      "step 10/4105\n",
      "step 11/4105\n",
      "step 12/4105\n",
      "step 13/4105\n",
      "step 14/4105\n",
      "step 15/4105\n",
      "step 16/4105\n",
      "step 17/4105\n",
      "step 18/4105\n",
      "step 19/4105\n",
      "step 20/4105\n",
      "step 21/4105\n",
      "step 22/4105\n",
      "step 23/4105\n",
      "step 24/4105\n",
      "step 25/4105\n",
      "step 26/4105\n",
      "step 27/4105\n",
      "step 28/4105\n",
      "step 29/4105\n",
      "step 30/4105\n",
      "step 31/4105\n",
      "step 32/4105\n",
      "step 33/4105\n",
      "step 34/4105\n",
      "step 35/4105\n",
      "step 36/4105\n",
      "step 37/4105\n",
      "step 38/4105\n",
      "step 39/4105\n",
      "step 40/4105\n",
      "step 41/4105\n",
      "step 42/4105\n",
      "step 43/4105\n",
      "step 44/4105\n",
      "step 45/4105\n",
      "step 46/4105\n",
      "step 47/4105\n",
      "step 48/4105\n",
      "step 49/4105\n",
      "step 50/4105\n",
      "step 51/4105\n",
      "step 52/4105\n",
      "step 53/4105\n",
      "step 54/4105\n",
      "step 55/4105\n",
      "step 56/4105\n",
      "step 57/4105\n",
      "step 58/4105\n",
      "step 59/4105\n",
      "step 60/4105\n",
      "step 61/4105\n",
      "step 62/4105\n",
      "step 63/4105\n",
      "step 64/4105\n",
      "step 65/4105\n",
      "step 66/4105\n",
      "step 67/4105\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(test_loader)\n",
    "max_steps = len(test_loader) \n",
    "print(max_steps)\n",
    "\n",
    "\n",
    "for step in range(max_steps):\n",
    "    print(\"step {}/{}\".format(step, max_steps))\n",
    "    batch = next(iterator)\n",
    "    \n",
    "    (tok_sentences, audio_features, seq_len, targets) = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reps_sentences = full_model.text_model(tok_sentences)['sentence_embedding']\n",
    "        reps_audio = full_model.audio_model((audio_features, seq_len))\n",
    "        \n",
    "        audio_logits =  (reps_audio @ reps_sentences.t()) * CFG.scale\n",
    "        text_logits = audio_logits.t()\n",
    "        e:\n",
    "        audio_logits = audio_logits / audio_logits.norm(dim=1, keepdim=True)\n",
    "        text_logits = text_logits / text_logits.norm(dim=1, keepdim=True)\n",
    "        \n",
    "        probs = audio_logits.softmax(dim=-1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "tensor(0.3672)\n"
     ]
    }
   ],
   "source": [
    "probs = audio_logits.softmax(dim=-1).cpu().numpy()\n",
    "# print(probs.argmax(axis=0))\n",
    "ground_truth = torch.arange(128)\n",
    "# print(ground_truth)\n",
    "\n",
    "\n",
    "print(\"accuracy: \")\n",
    "acc = torch.eq(torch.tensor(probs.argmax(axis=0)), ground_truth).sum() / ground_truth.shape[0]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings of shows in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cudacheck] Is cuda available?  False\n",
      "torch.Size([128, 768])\n",
      "torch.Size([128, 768])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_text = []\n",
    "processed_audio = []\n",
    "\n",
    "topic_norm_reps_text = []\n",
    "topic_norm_reps_audio = []\n",
    "\n",
    "matrix_targets = []\n",
    "iterator = iter(test_loader)\n",
    "for step in range(2):\n",
    "    batch = next(iterator)\n",
    "    \n",
    "    (tok_sentences, audio_features, seq_len, targets) = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"[del] get embeds: \")\n",
    "        reps_sentences = full_model.text_model(tok_sentences)['sentence_embedding']\n",
    "        # embeds = self.model.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #reps_sentences = reps_sentences.detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "        reps_audio = full_model.audio_model((audio_features, seq_len))\n",
    "        \n",
    "        # Normalized representations\n",
    "        topic_norm_reps_text.append(reps_sentences / reps_sentences.norm(dim=1, keepdim=True))\n",
    "        topic_norm_reps_audio.append(reps_audio / reps_audio.norm(dim=1, keepdim=True))\n",
    "        \n",
    "        #print(reps_audio.shape)\n",
    "        audio_logits =  (reps_audio @ reps_sentences.t()) * CFG.scale\n",
    "        text_logits = audio_logits.t()\n",
    "        \n",
    "        matrix_targets.extend(targets)\n",
    "        \n",
    "        \n",
    "#         audio_logits = audio_logits / audio_logits.norm(dim=1, keepdim=True)\n",
    "#         text_logits = text_logits / text_logits.norm(dim=1, keepdim=True)\n",
    "        \n",
    "#         #probs = audio_logits.softmax(dim=-1).cpu().numpy()\n",
    "        \n",
    "#         processed_text.append(audio_logits)\n",
    "        \n",
    "#         processed_audio.append(audio_logits)\n",
    "        \n",
    "#     print(probs)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 768])\n",
      "torch.Size([256, 768])\n",
      "torch.Size([256, 768])\n"
     ]
    }
   ],
   "source": [
    "print(topic_norm_reps_audio[0].shape)\n",
    "\n",
    "topic_norm_reps_audio = torch.cat(topic_norm_reps_audio, dim=0)\n",
    "print(topic_norm_reps_audio.shape)\n",
    "\n",
    "topic_norm_reps_text = torch.cat(topic_norm_reps_text, dim=0)\n",
    "print(topic_norm_reps_text.shape)\n",
    "\n",
    "# probs = audio.softmax(dim=-1).cpu().numpy()\n",
    "# print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity = text.cpu().numpy().T @  audio.cpu().numpy()\n",
    "\n",
    "\n",
    "# print(matrix_targets)\n",
    "# topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = similarity.argmax(axis=0)\n",
    "# ground_truth = torch.arange(similarity.shape[0])\n",
    "\n",
    "# stats = torch.eq(torch.tensor(result), ground_truth).sum()\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/troep/lib/python3.8/site-packages/pandas/core/indexing.py:1684: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "/opt/miniconda3/envs/troep/lib/python3.8/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/opt/miniconda3/envs/troep/lib/python3.8/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>unk</th>\n",
       "      <th>episode_uri_time</th>\n",
       "      <th>score</th>\n",
       "      <th>bin_score</th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>time</th>\n",
       "      <th>ep_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>75cpxDXpVz9ScTVNIWz5d6_420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75cpxDXpVz9ScTVNIWz5d6</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_1980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7541</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_2040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>2040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7543</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_2160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>2160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num  unk             episode_uri_time  score  bin_score  \\\n",
       "4767   34    0   75cpxDXpVz9ScTVNIWz5d6_420      0          0   \n",
       "7540   13    0  3QGmWCiVOsKzY85lnSglF6_1980      0          0   \n",
       "7541   13    0  3QGmWCiVOsKzY85lnSglF6_2040      0          0   \n",
       "7542   13    0  3QGmWCiVOsKzY85lnSglF6_2100      0          0   \n",
       "7543   13    0  3QGmWCiVOsKzY85lnSglF6_2160      0          0   \n",
       "\n",
       "                 episode_uri  time  ep_score  \n",
       "4767  75cpxDXpVz9ScTVNIWz5d6   420         0  \n",
       "7540  3QGmWCiVOsKzY85lnSglF6  1980         0  \n",
       "7541  3QGmWCiVOsKzY85lnSglF6  2040         0  \n",
       "7542  3QGmWCiVOsKzY85lnSglF6  2100         0  \n",
       "7543  3QGmWCiVOsKzY85lnSglF6  2160         0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Validation DF\n",
    "ids_we_can_use = [m.split('_')[0] for m in matrix_targets]\n",
    "val_df = topics_df_targets[topics_df_targets['episode_uri'].isin(ids_we_can_use)]\n",
    "\n",
    "### TODO: dit naar boven\n",
    "positive_episodes = val_df.loc[val_df['bin_score'] == 1].copy()\n",
    "positive_eplist = positive_episodes['episode_uri'].tolist()\n",
    "\n",
    "\n",
    "for i, row in val_df.iterrows():\n",
    "    ifor_val = 0\n",
    "    if row['episode_uri'] in positive_eplist:\n",
    "        #print(\"IN TESTLIST\")\n",
    "        ifor_val = 1\n",
    "    val_df.loc[i,'ep_score'] = ifor_val\n",
    "    \n",
    "val_df.ep_score = val_df.ep_score.astype(int)\n",
    "val_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  8398,  2655,  5969,  2343,   102,     0,     0],\n",
      "        [  101, 10321, 22061,  5823,  5320,   102,     0,     0],\n",
      "        [  101,  2129,  2000,  5660,  4977,   102,     0,     0],\n",
      "        [  101, 10047,  5521,  4967,  2476,   102,     0,     0],\n",
      "        [  101,  4319, 13449,  7233,   102,     0,     0,     0],\n",
      "        [  101,  2379,  2331,  6322,   102,     0,     0,     0],\n",
      "        [  101, 16110,  2055, 16110,  2015,   102,     0,     0],\n",
      "        [  101,  5320,  1998,  9740,  1997,  3748, 26332,   102],\n",
      "        [  101,  2051,  2090,  6295,   102,     0,     0,     0],\n",
      "        [  101,  2308,  1999,  7872,   102,     0,     0,     0],\n",
      "        [  101,  9932,  1999,  9871,   102,     0,     0,     0],\n",
      "        [  101,  3465,  1997,  2775, 16302,   102,     0,     0],\n",
      "        [  101,  2238, 17389,  3372,  2232,   102,     0,     0],\n",
      "        [  101, 24188, 25083,  8516, 14633,   102,     0,     0],\n",
      "        [  101, 10289,  8214,  2543,   102,     0,     0,     0],\n",
      "        [  101,  2605,  3756, 17447,  8090,   102,     0,     0],\n",
      "        [  101,  2304,  3268,  3043,   102,     0,     0,     0],\n",
      "        [  101,  3960, 19133,   102,     0,     0,     0,     0],\n",
      "        [  101,  2942,  2916,  6186,  3441,   102,     0,     0],\n",
      "        [  101, 10930,  1011, 10930,  8738,  2075,   102,     0],\n",
      "        [  101, 14398,  1999,  2710,   102,     0,     0,     0],\n",
      "        [  101,  2388,  9021,   102,     0,     0,     0,     0],\n",
      "        [  101,  7570,  7352, 16186,  3752,  4456,   102,     0],\n",
      "        [  101,  7230,  2208,  2285,  2570,   102,     0,     0],\n",
      "        [  101,  1044, 24887,  3068,  4483,  2964,   102,     0],\n",
      "        [  101, 14414,  3441,  1998, 11834,   102,     0,     0],\n",
      "        [  101,  2542,  7016,  2489,   102,     0,     0,     0],\n",
      "        [  101, 19888, 10085,  3126,  7389,  5666, 10831,   102],\n",
      "        [  101,  4030,  3604,   102,     0,     0,     0,     0],\n",
      "        [  101, 16165,  8906,   102,     0,     0,     0,     0],\n",
      "        [  101,  2591,  2865,  5821,   102,     0,     0,     0],\n",
      "        [  101, 13734,  5996,   102,     0,     0,     0,     0],\n",
      "        [  101, 13938,  2080,  2833, 28847,   102,     0,     0],\n",
      "        [  101,  1042, 16363,  2782,   102,     0,     0,     0],\n",
      "        [  101,  4291,  4290,  8090,   102,     0,     0,     0],\n",
      "        [  101, 15060,  4038,  2569,   102,     0,     0,     0],\n",
      "        [  101, 21168,  4389,  4515,   102,     0,     0,     0],\n",
      "        [  101,  5284, 27565,  3566,   102,     0,     0,     0],\n",
      "        [  101, 16596,  1011, 10882,  3166,  4357,  7733,   102],\n",
      "        [  101,  9997,  3389,  3185,  3556,   102,     0,     0],\n",
      "        [  101, 16215, 16338,  3573,  5437,   102,     0,     0],\n",
      "        [  101,  3023,  3457,  9574, 26760,  8113,   102,     0],\n",
      "        [  101, 19483,  3239,  8003,   102,     0,     0,     0],\n",
      "        [  101,  6904, 14194,  2072,  4357,   102,     0,     0],\n",
      "        [  101,  6749,  2808,  2005, 17633,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "9\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "10\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  7\n",
      "torch.Size([7, 1024])\n",
      "11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "12\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "13\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "14\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "15\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "16\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  6\n",
      "torch.Size([6, 1024])\n",
      "17\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "19\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "20\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "21\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  2\n",
      "torch.Size([2, 1024])\n",
      "22\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "23\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "26\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  2\n",
      "torch.Size([2, 1024])\n",
      "27\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "28\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "29\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "30\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  2\n",
      "torch.Size([2, 1024])\n",
      "31\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "32\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  6\n",
      "torch.Size([6, 1024])\n",
      "33\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  7\n",
      "torch.Size([7, 1024])\n",
      "34\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "35\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "36\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "37\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  2\n",
      "torch.Size([2, 1024])\n",
      "38\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "39\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "40\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  2\n",
      "torch.Size([2, 1024])\n",
      "41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "42\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "43\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "44\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "45\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "46\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "47\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  5\n",
      "torch.Size([5, 1024])\n",
      "48\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "49\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  4\n",
      "torch.Size([4, 1024])\n",
      "51\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "52\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  3\n",
      "torch.Size([3, 1024])\n",
      "53\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "LEN:  6\n",
      "torch.Size([6, 1024])\n",
      "[tensor([[0.0000, 0.2856, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0014, 0.0319, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2942, 0.2688, 0.0342,  ..., 0.1611, 0.0359, 0.0000],\n",
      "        [0.2297, 0.5664, 0.1956,  ..., 0.4385, 0.0600, 0.0000],\n",
      "        [0.1868, 0.2480, 0.2133,  ..., 0.0559, 0.0000, 0.0000]]), tensor([[0.0000, 0.2771, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2825, 0.8784, 0.0000,  ..., 0.0788, 0.0301, 0.0000],\n",
      "        [0.0958, 0.7231, 0.0000,  ..., 0.0125, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.8584, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.5176, 0.0000,  ..., 0.0359, 0.0000, 0.0000],\n",
      "        [0.0294, 0.8135, 0.0299,  ..., 0.0383, 0.0000, 0.0000]]), tensor([[0.1528, 0.3850, 0.0000,  ..., 0.0097, 0.0000, 0.0000],\n",
      "        [0.0868, 0.0342, 0.0000,  ..., 0.1755, 0.1281, 0.0000],\n",
      "        [0.1438, 0.5625, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0000, 1.1465, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7910, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1108, 0.7544, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0336, 0.5688, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0734, 0.4927, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2017, 0.2949, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1508, 0.0493, 0.0000,  ..., 0.0260, 0.0000, 0.0000]]), tensor([[0.1471, 0.6626, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1273, 0.1550, 0.0000,  ..., 0.2915, 0.2209, 0.0000],\n",
      "        [0.0684, 0.1958, 0.0112,  ..., 0.2070, 0.0015, 0.0000],\n",
      "        [0.0632, 1.1074, 0.0032,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0361, 0.8364, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0578, 0.6895, 0.0000,  ..., 0.0757, 0.1002, 0.0000],\n",
      "        [0.1824, 1.1436, 0.0000,  ..., 0.0370, 0.0379, 0.0000],\n",
      "        [0.0276, 0.8188, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0909, 0.6021, 0.0887,  ..., 0.0642, 0.0000, 0.0000]]), tensor([[0.0922, 1.0859, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1488, 0.1938, 0.0000,  ..., 0.0015, 0.0000, 0.0000],\n",
      "        [0.3098, 0.3755, 0.0000,  ..., 0.0000, 0.0242, 0.0000],\n",
      "        [0.0230, 0.4861, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0377, 0.6001, 0.0696,  ..., 0.0584, 0.0000, 0.0000]]), tensor([[0.0000, 0.1222, 0.0000,  ..., 0.0292, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3357, 0.0000,  ..., 0.0147, 0.0146, 0.0000],\n",
      "        [0.1316, 0.4253, 0.0000,  ..., 0.0000, 0.0081, 0.0000],\n",
      "        [0.0000, 0.7061, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.1226, 0.6655, 0.0000,  ..., 0.0000, 0.0057, 0.0000],\n",
      "        [0.2474, 0.7280, 0.0000,  ..., 0.0015, 0.0394, 0.0000],\n",
      "        [0.2448, 0.7017, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0226, 0.5762, 0.0112,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0421, 1.0137, 0.0400,  ..., 0.3203, 0.0000, 0.0000],\n",
      "        [0.3108, 0.2483, 0.0061,  ..., 0.0287, 0.0093, 0.0000]]), tensor([[0.0658, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0543, 0.0391, 0.0000,  ..., 0.2263, 0.0253, 0.0000],\n",
      "        [0.1825, 0.3096, 0.0000,  ..., 0.0000, 0.0724, 0.0000]]), tensor([[0.1614, 0.6450, 0.0000,  ..., 0.0202, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8955, 0.0037,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.3042, 0.1991, 0.0000,  ..., 0.0000, 0.0493, 0.0000],\n",
      "        [0.0521, 0.1935, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1026, 0.3511, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1309, 0.2495, 0.2825,  ..., 0.0366, 0.0000, 0.0000]]), tensor([[0.2430, 0.6494, 0.0000,  ..., 0.0339, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0020, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3228, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0000, 0.5869, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1057, 0.5815, 0.0000,  ..., 0.0079, 0.0000, 0.0000],\n",
      "        [0.1595, 0.1385, 0.0595,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1676, 0.3137, 0.0665,  ..., 0.0302, 0.0000, 0.0000],\n",
      "        [0.0025, 0.7417, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.2349, 0.1674, 0.0051,  ..., 0.0000, 0.0246, 0.0069],\n",
      "        [0.0165, 0.0053, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1891, 0.5576, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.1231, 1.3408, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3237, 0.4924, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.4966, 1.1875, 0.0000,  ..., 0.0000, 0.0227, 0.0000],\n",
      "        [0.2930, 0.7563, 0.0384,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6050, 0.0686, 0.1692,  ..., 0.0040, 0.0047, 0.0000],\n",
      "        [0.1781, 0.8350, 0.0000,  ..., 0.1459, 0.0091, 0.0000],\n",
      "        [0.0000, 0.2998, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0928, 0.8901, 0.0081,  ..., 0.0300, 0.0000, 0.0000],\n",
      "        [0.0272, 0.3511, 0.0058,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1059, 0.5264, 0.0000,  ..., 0.0153, 0.0073, 0.0000]]), tensor([[0.0000, 0.4534, 0.0000,  ..., 0.0387, 0.0000, 0.0000],\n",
      "        [0.0840, 0.2788, 0.2354,  ..., 0.2654, 0.0066, 0.0000],\n",
      "        [0.1252, 0.3462, 0.3486,  ..., 0.0543, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.1835, 1.4326, 0.0000,  ..., 0.0025, 0.0080, 0.0000],\n",
      "        [0.0020, 0.3237, 0.0163,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0390, 0.4346, 0.0000,  ..., 0.0000, 0.0239, 0.0000],\n",
      "        [0.0059, 1.0654, 0.0000,  ..., 0.1372, 0.0132, 0.0088],\n",
      "        [0.0232, 0.1674, 0.0000,  ..., 0.0521, 0.0000, 0.0000],\n",
      "        [0.1554, 0.7891, 0.0000,  ..., 0.0533, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0049, 0.4939, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0533, 0.3896, 0.0000,  ..., 0.2529, 0.0435, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1011, 0.0462, 0.0000,  ..., 0.0480, 0.0092, 0.0000],\n",
      "        [0.0861, 0.0361, 0.0486,  ..., 0.1577, 0.0000, 0.0000],\n",
      "        [0.2255, 0.0576, 0.0030,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.1793, 0.5239, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1564, 0.4075, 0.0000,  ..., 0.0390, 0.0000, 0.0000],\n",
      "        [0.4082, 0.2297, 0.0000,  ..., 0.4814, 0.1855, 0.0000],\n",
      "        ...,\n",
      "        [0.0245, 0.0792, 0.0058,  ..., 0.2222, 0.0000, 0.0000],\n",
      "        [0.2224, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2551, 0.6221, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.3411, 0.1741, 0.0087,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1445, 0.0424, 0.0000,  ..., 0.0102, 0.0000, 0.0000],\n",
      "        [0.0402, 1.2344, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0903, 0.1548, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0019, 0.3003, 0.0243,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.1945, 1.3545, 0.0000,  ..., 0.0000, 0.0309, 0.0000],\n",
      "        [0.0477, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1875, 0.9360, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0308, 0.3621, 0.0000,  ..., 0.3948, 0.1331, 0.0000],\n",
      "        [0.0096, 0.9766, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0992, 0.5000, 0.0000,  ..., 0.0320, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0963, 0.0569,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0646, 1.2217, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3293, 1.1133, 0.0000,  ..., 0.0000, 0.0188, 0.0000]]), tensor([[0.0674, 0.1354, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1820, 0.1886, 0.0000,  ..., 0.1539, 0.1401, 0.0000],\n",
      "        [0.4351, 0.1580, 0.0070,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3105, 0.1051, 0.0000,  ..., 0.2133, 0.0000, 0.0000]]), tensor([[0.4768, 0.6460, 0.0000,  ..., 0.0323, 0.0000, 0.0000],\n",
      "        [0.1969, 0.3823, 0.0000,  ..., 0.0775, 0.0092, 0.0000],\n",
      "        [0.0576, 0.0944, 0.1033,  ..., 0.0435, 0.0000, 0.0000],\n",
      "        [0.0284, 1.1201, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0678, 0.7119, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1489, 0.2585, 0.0000,  ..., 0.0363, 0.0000, 0.0000]]), tensor([[0.1731, 0.7490, 0.0000,  ..., 0.2639, 0.0000, 0.0000],\n",
      "        [0.1565, 0.2986, 0.0000,  ..., 0.0282, 0.0000, 0.0000],\n",
      "        [0.2742, 0.4314, 0.0000,  ..., 0.0053, 0.1696, 0.0000],\n",
      "        [0.2693, 0.4487, 0.0135,  ..., 0.0209, 0.0000, 0.0000]]), tensor([[0.0000, 1.0664, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0122, 0.8853, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1725, 0.6655, 0.0779,  ..., 0.1589, 0.0000, 0.0000]]), tensor([[0.0000, 0.6660, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0652, 0.0093, 0.0000,  ..., 0.5488, 0.2749, 0.0036],\n",
      "        [0.0000, 0.2820, 0.0195,  ..., 0.0840, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0126, 0.0000, 0.0000]]), tensor([[0.1689, 0.1884, 0.0000,  ..., 0.3230, 0.0720, 0.0000],\n",
      "        [0.0334, 0.3335, 0.0000,  ..., 0.1068, 0.0023, 0.0000],\n",
      "        [0.1116, 0.2515, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3733, 0.1898, 0.0000,  ..., 0.0690, 0.0088, 0.0000]]), tensor([[0.0749, 0.5762, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0039, 0.4006, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8682, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.1113, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.3391, 1.0264, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0562, 0.1776, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0124, 0.5596, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.1653, 0.3586, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0663, 0.4998, 0.0000,  ..., 0.0072, 0.0000, 0.0000],\n",
      "        [0.1652, 0.5737, 0.0000,  ..., 0.1038, 0.0000, 0.0000],\n",
      "        [0.0414, 0.8384, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.1641, 0.0123,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0143, 0.8369, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1881, 0.3660, 0.0013,  ..., 0.0477, 0.0000, 0.0000],\n",
      "        [0.2932, 0.3213, 0.0000,  ..., 0.0670, 0.0000, 0.0000],\n",
      "        [0.0630, 0.5552, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0000, 0.3840, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3594, 0.1233, 0.0000,  ..., 0.1140, 0.0555, 0.0000],\n",
      "        [0.1754, 0.5513, 0.0000,  ..., 0.0000, 0.0093, 0.0000]]), tensor([[0.1561, 0.0073, 0.0000,  ..., 0.0000, 0.0167, 0.0000],\n",
      "        [0.0341, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0137, 0.2140, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0946, 0.5239, 0.0503,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[0.0592, 0.9224, 0.0873,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2139, 0.7871, 0.0000,  ..., 0.0247, 0.0000, 0.0000],\n",
      "        [0.1633, 0.5239, 0.0304,  ..., 0.1008, 0.0431, 0.0000]]), tensor([[0.2744, 0.4216, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2452, 0.3416, 0.0280,  ..., 0.2297, 0.2524, 0.0000],\n",
      "        [0.2087, 0.8237, 0.0000,  ..., 0.0286, 0.0000, 0.0000]]), tensor([[0.2864, 0.5771, 0.0000,  ..., 0.4993, 0.0197, 0.0000],\n",
      "        [0.0728, 0.6055, 0.0000,  ..., 0.0198, 0.0000, 0.0000],\n",
      "        [0.3469, 0.3193, 0.0000,  ..., 0.1278, 0.0000, 0.0000],\n",
      "        [0.1010, 0.9849, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5312, 0.1403,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])]\n"
     ]
    }
   ],
   "source": [
    "# Create text embeddings of queries\n",
    "query_field = 'query'\n",
    "query_nr = 0\n",
    "query = topics_df[query_field].iloc[query_nr]\n",
    "\n",
    "\n",
    "queries = topics_df[query_field][:45].tolist()\n",
    "tokenized_queries = tokenizer(\n",
    "    queries, padding=True, truncation=True, max_length=32, return_tensors='pt', return_token_type_ids=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(tokenized_queries)\n",
    "\n",
    "query_yamnets = []\n",
    "query_lengths = []\n",
    "for idx, row in topics_df[:45].iterrows():\n",
    "    query_num = row.num\n",
    "    print(query_num)\n",
    "    query_embed_path  = os.path.join(conf.yamnet_query_embed_path, str(query_num) + \".h5\")\n",
    "    inbetween_yamnet_embeds = pd.read_hdf(query_embed_path)\n",
    "    print(type(inbetween_yamnet_embeds))\n",
    "    print(\"LEN: \", len(inbetween_yamnet_embeds))\n",
    "    query_lengths.append(len(inbetween_yamnet_embeds))\n",
    "    tmp = torch.Tensor(inbetween_yamnet_embeds.values)\n",
    "    print(tmp.shape)\n",
    "    query_yamnets.append(tmp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #lengths.append(len(example[1]))\n",
    "\n",
    "print(query_yamnets)\n",
    "\n",
    "padded_query_yamnets = pad_sequence(query_yamnets, batch_first=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = []\n",
    "\n",
    "query_audio = []\n",
    "query_field = 'query'\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "\n",
    "    # print(\"[del] get embeds: \")\n",
    "    reps_sentences = full_model.text_model(tokenized_queries)['sentence_embedding']\n",
    "    # embeds = self.model.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    #reps_sentences = reps_sentences.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    reps_audio = full_model.audio_model((padded_query_yamnets, query_lengths))\n",
    "\n",
    "\n",
    "    audio_logits =  (reps_audio @ reps_sentences.t()) * CFG.scale\n",
    "    text_logits = audio_logits.t()\n",
    "\n",
    "\n",
    "    audio_logits = audio_logits / audio_logits.norm(dim=1, keepdim=True)\n",
    "    text_logits = text_logits / text_logits.norm(dim=1, keepdim=True)\n",
    "\n",
    "    #probs = audio_logits.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    query_text_logits = text_logits\n",
    "    query_audio_logits = audio_logits\n",
    "    \n",
    "    query_norm_reps_audio = reps_audio / reps_audio.norm(dim=1, keepdim=True)\n",
    "    query_norm_reps_text = reps_sentences / reps_sentences.norm(dim=1, keepdim=True)\n",
    "#     print(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2221, -0.0591, -0.0153,  ...,  0.0341, -0.2017, -0.0945],\n",
      "        [ 0.3498,  0.0355,  0.0704,  ...,  0.0071,  0.1612, -0.0263],\n",
      "        [-0.1308,  0.0089,  0.1843,  ...,  0.0023,  0.2269,  0.0049],\n",
      "        ...,\n",
      "        [-0.1502,  0.0006,  0.0308,  ...,  0.2366,  0.0736,  0.1026],\n",
      "        [-0.0960,  0.0699,  0.1117,  ..., -0.0189,  0.1210,  0.0348],\n",
      "        [ 0.2057,  0.1482,  0.0596,  ..., -0.0126,  0.1532,  0.0316]])\n",
      "torch.Size([45, 45])\n",
      "tensor([[ 0.0934,  0.3085, -0.0729,  ..., -0.0587, -0.0434,  0.2053],\n",
      "        [-0.0784,  0.0988,  0.0156,  ...,  0.0007,  0.0998,  0.4668],\n",
      "        [-0.0064,  0.0618,  0.1023,  ...,  0.0120,  0.0503,  0.0592],\n",
      "        ...,\n",
      "        [ 0.0472,  0.0205,  0.0043,  ...,  0.3046, -0.0281, -0.0415],\n",
      "        [-0.0378,  0.0634,  0.0564,  ...,  0.0128,  0.0244,  0.0682],\n",
      "        [-0.1632, -0.0952,  0.0112,  ...,  0.1646,  0.0646,  0.1292]])\n",
      "torch.Size([45, 45])\n"
     ]
    }
   ],
   "source": [
    "print(query_text_logits)\n",
    "print(query_text_logits.shape)\n",
    "\n",
    "\n",
    "print(query_audio_logits)\n",
    "print(query_audio_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 768])\n",
      "torch.Size([45, 768])\n"
     ]
    }
   ],
   "source": [
    "print(query_norm_reps_audio.shape)\n",
    "print(query_norm_reps_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done query 0, p@10 0.0, ndcg: 0.0\n",
      "done query 1, p@10 0.0, ndcg: 0.0\n",
      "done query 2, p@10 0.0, ndcg: 0.0\n",
      "done query 3, p@10 0.0, ndcg: 0.0\n",
      "done query 4, p@10 0.0, ndcg: 0.0\n",
      "done query 5, p@10 0.0, ndcg: 0.0\n",
      "done query 6, p@10 0.0, ndcg: 0.0\n",
      "done query 7, p@10 0.0, ndcg: 0.0\n",
      "done query 8, p@10 0.0, ndcg: 0.0\n",
      "done query 9, p@10 0.0, ndcg: 0.0\n",
      "done query 10, p@10 0.0, ndcg: 0.0\n",
      "done query 11, p@10 0.0, ndcg: 0.0\n",
      "done query 12, p@10 0.0, ndcg: 0.0\n",
      "done query 13, p@10 0.3, ndcg: 0.0\n",
      "done query 14, p@10 0.0, ndcg: 0.0\n",
      "done query 15, p@10 0.0, ndcg: 0.0\n",
      "done query 16, p@10 0.0, ndcg: 0.0\n",
      "done query 17, p@10 0.0, ndcg: 0.0\n",
      "done query 18, p@10 0.0, ndcg: 0.0\n",
      "done query 19, p@10 0.0, ndcg: 0.0\n",
      "done query 20, p@10 0.0, ndcg: 0.0\n",
      "done query 21, p@10 0.0, ndcg: 0.0\n",
      "done query 22, p@10 0.0, ndcg: 0.0\n",
      "done query 23, p@10 0.0, ndcg: 0.0\n",
      "done query 24, p@10 0.0, ndcg: 0.0\n",
      "done query 25, p@10 0.0, ndcg: 0.0\n",
      "done query 26, p@10 0.0, ndcg: 0.0\n",
      "done query 27, p@10 0.0, ndcg: 0.0\n",
      "done query 28, p@10 0.0, ndcg: 0.0\n",
      "done query 29, p@10 0.0, ndcg: 0.0\n",
      "done query 30, p@10 0.0, ndcg: 0.0\n",
      "done query 31, p@10 0.0, ndcg: 0.0\n",
      "done query 32, p@10 0.0, ndcg: 0.0\n",
      "done query 33, p@10 0.0, ndcg: 0.0\n",
      "done query 34, p@10 0.6, ndcg: 0.0\n",
      "done query 35, p@10 0.3, ndcg: 0.0986175845507522\n",
      "done query 36, p@10 0.0, ndcg: 0.0\n",
      "done query 37, p@10 0.0, ndcg: 0.0\n",
      "done query 38, p@10 0.0, ndcg: 0.0\n",
      "done query 39, p@10 0.0, ndcg: 0.0\n",
      "done query 40, p@10 0.0, ndcg: 0.0\n",
      "done query 41, p@10 0.0, ndcg: 0.0\n",
      "done query 42, p@10 0.0, ndcg: 0.0\n",
      "done query 43, p@10 0.0, ndcg: 0.0\n",
      "done query 44, p@10 0.0, ndcg: 0.0\n"
     ]
    }
   ],
   "source": [
    "from torch import topk\n",
    "k = 50\n",
    "\n",
    "pred_episodes = {}\n",
    "\n",
    "similarity = 100 * query_norm_reps_text @ topic_norm_reps_text.T\n",
    "# print(similarity)\n",
    "# print(similarity.shape)\n",
    "\n",
    "probs = similarity.softmax(dim=-1).cpu()\n",
    "#print(probs.argmax(axis=1))\n",
    "\n",
    "\n",
    "top_probs, top_labels = probs.topk(k, dim=-1)\n",
    "# ground_truth = torch.arange(128)\n",
    "# print(ground_truth)\n",
    "\n",
    "for num in range(45):\n",
    "    query = topics_df[query_field][num]\n",
    "    \n",
    "    pred_ind = top_labels[num].tolist()\n",
    "    #print(\"pred: \", pred_ind)\n",
    "    \n",
    "    #pred_targs = matrix_targets[pred_ind]\n",
    "    pred_epis = [matrix_targets[val].split('_')[0] for val in pred_ind]\n",
    "\n",
    "    \n",
    "    tmp = val_df[(val_df.num == num) & (val_df.ep_score==1)]\n",
    "    tmp = tmp['episode_uri'].tolist()\n",
    "    num_episodes_relevant = len(set(tmp))\n",
    "    \n",
    "    ep_scores = []\n",
    "    for episode_uri in pred_epis:\n",
    "        ep_score_row = val_df.loc[val_df['episode_uri'] == episode_uri]\n",
    "        if len(ep_score_row) > 0 and ep_score_row.num.values[0] == num:\n",
    "            ep_scores.append(1)\n",
    "        else:\n",
    "            ep_scores.append(0)\n",
    "    \n",
    "    pred_episodes[query] = {}\n",
    "    pred_episodes[query]['episodes'] = [matrix_targets[val].split('_')[0] for val in pred_ind]\n",
    "    pred_episodes[query]['ep_score'] = ep_scores\n",
    "    \n",
    "    pred_episodes[query]['prec@3'] = precision_at_k(ep_scores, 3)\n",
    "    pred_episodes[query]['prec@10'] = precision_at_k(ep_scores, 10)\n",
    "    pred_episodes[query]['prec@30'] = precision_at_k(ep_scores, 30)\n",
    "    \n",
    "\n",
    "    targets = [[1] * num_episodes_relevant + [0] * (len(ep_scores) - num_episodes_relevant)]\n",
    "    ndcg_ep_score = ndcg_score(targets, [ep_scores], k=30)\n",
    "    pred_episodes[query]['ndc'] = ndcg_ep_score\n",
    "    print(\"done query {}, p@10 {}, ndcg: {}\".format(num, pred_episodes[query]['prec@10'], ndcg_ep_score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "# top_probs, top_labels = text_probs.cpu().topk(5, dim=-1)\n",
    "# bels = text_probs.cpu().topk(5, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trump call ukrainian president': ['75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6'],\n",
       " 'boeing 737 crash causes': ['75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9'],\n",
       " 'how to cook turkey': ['75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9'],\n",
       " 'imran khan career': ['75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9'],\n",
       " 'drug addiction recovery': ['20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '3QGmWCiVOsKzY85lnSglF6',\n",
       "  '75cpxDXpVz9ScTVNIWz5d6',\n",
       "  '20Rxox5JAR894PcIMGpsV9',\n",
       "  '20Rxox5JAR894PcIMGpsV9']}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>unk</th>\n",
       "      <th>episode_uri_time</th>\n",
       "      <th>score</th>\n",
       "      <th>bin_score</th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>time</th>\n",
       "      <th>ep_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>75cpxDXpVz9ScTVNIWz5d6_420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75cpxDXpVz9ScTVNIWz5d6</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9_1020</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9_1380</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9</td>\n",
       "      <td>1380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num  unk             episode_uri_time  score  bin_score  \\\n",
       "4767   34    0   75cpxDXpVz9ScTVNIWz5d6_420      0          0   \n",
       "5464   35    0  20Rxox5JAR894PcIMGpsV9_1020      3          1   \n",
       "5465   35    0  20Rxox5JAR894PcIMGpsV9_1380      3          1   \n",
       "\n",
       "                 episode_uri  time  ep_score  \n",
       "4767  75cpxDXpVz9ScTVNIWz5d6   420         0  \n",
       "5464  20Rxox5JAR894PcIMGpsV9  1020         1  \n",
       "5465  20Rxox5JAR894PcIMGpsV9  1380         1  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "None\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def precision_at_k(predicted, k):\n",
    "    if k == 0:\n",
    "        print(\"precision from k ===0?\")\n",
    "        raise\n",
    "    pred = (predicted[:k])\n",
    "    relevant = np.sum(pred)\n",
    "    num_recommended = float(k)\n",
    "    p_at_k = relevant / num_recommended\n",
    "    return p_at_k\n",
    "\n",
    "# Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)\n",
    "def recall_at_k(predicted, num_relevant, k):\n",
    "    if num_relevant == 0:\n",
    "        return None\n",
    "    pred = (predicted[:k])\n",
    "    relevant = np.sum(pred)\n",
    "    r_at_k = relevant / num_relevant\n",
    "\n",
    "    return r_at_k\n",
    "\n",
    "\n",
    "scores = [[1,1,1,0,1]]\n",
    "targets = [[1,1,1,1,0]]\n",
    "\n",
    "print(precision_at_k(scores[0], 5))\n",
    "print(recall_at_k(scores[0], 0, 2))\n",
    "ndcg = ndcg_score(targets, scores, k=3)\n",
    "print(ndcg)\n",
    "# print(es_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/troep/lib/python3.8/site-packages/pandas/core/indexing.py:1684: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "/opt/miniconda3/envs/troep/lib/python3.8/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/opt/miniconda3/envs/troep/lib/python3.8/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>unk</th>\n",
       "      <th>episode_uri_time</th>\n",
       "      <th>score</th>\n",
       "      <th>bin_score</th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>time</th>\n",
       "      <th>ep_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>75cpxDXpVz9ScTVNIWz5d6_420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75cpxDXpVz9ScTVNIWz5d6</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9_1020</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9_1380</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20Rxox5JAR894PcIMGpsV9</td>\n",
       "      <td>1380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_1980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7541</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_2040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>2040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7543</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6_2160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3QGmWCiVOsKzY85lnSglF6</td>\n",
       "      <td>2160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num  unk             episode_uri_time  score  bin_score  \\\n",
       "4767   34    0   75cpxDXpVz9ScTVNIWz5d6_420      0          0   \n",
       "5464   35    0  20Rxox5JAR894PcIMGpsV9_1020      3          1   \n",
       "5465   35    0  20Rxox5JAR894PcIMGpsV9_1380      3          1   \n",
       "7540   13    0  3QGmWCiVOsKzY85lnSglF6_1980      0          0   \n",
       "7541   13    0  3QGmWCiVOsKzY85lnSglF6_2040      0          0   \n",
       "7542   13    0  3QGmWCiVOsKzY85lnSglF6_2100      0          0   \n",
       "7543   13    0  3QGmWCiVOsKzY85lnSglF6_2160      0          0   \n",
       "\n",
       "                 episode_uri  time  ep_score  \n",
       "4767  75cpxDXpVz9ScTVNIWz5d6   420         0  \n",
       "5464  20Rxox5JAR894PcIMGpsV9  1020         1  \n",
       "5465  20Rxox5JAR894PcIMGpsV9  1380         1  \n",
       "7540  3QGmWCiVOsKzY85lnSglF6  1980         0  \n",
       "7541  3QGmWCiVOsKzY85lnSglF6  2040         0  \n",
       "7542  3QGmWCiVOsKzY85lnSglF6  2100         0  \n",
       "7543  3QGmWCiVOsKzY85lnSglF6  2160         0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get score from val df\n",
    "\n",
    "3QGmWCiVOsKzY85lnSglF6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:troep] *",
   "language": "python",
   "name": "conda-env-troep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
