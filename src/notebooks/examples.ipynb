{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c698591",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "In this notebook some examples are generated. Given a query, the model returns similar sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92db5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import random \n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils import data as datautil\n",
    "from torch.utils.data import Sampler, BatchSampler, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "from dacite import from_dict\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy import spatial\n",
    "\n",
    "sys.path.append('../') \n",
    "from train import mmModule, multimodal_loss, Cfg\n",
    "from utils import read_metadata_subset, find_paths, randomize_model\n",
    "from dataloader import MMloader\n",
    "from evaluate_topic import Evaluator\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "conf = OmegaConf.load(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a8419",
   "metadata": {},
   "source": [
    "### Relocate some configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f0ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[utils] metadata loaded  105360\n",
      "[utils] topics_df_targets loaded for test set 9426\n",
      "[utils] metadata_subset loaded  9426\n"
     ]
    }
   ],
   "source": [
    "# Rename configurations used, since they are one folder up.\n",
    "conf.dataset_path = os.path.join(\"../\", conf.dataset_path)\n",
    "conf.sp_path = os.path.join(\"../\", conf.sp_path)\n",
    "conf.yamnet_query_embed_path = os.path.join(\"../\", conf.yamnet_query_embed_path)\n",
    "conf.yamnet_descr_embed_path = os.path.join(\"../\", conf.yamnet_descr_embed_path)\n",
    "\n",
    "conf.sent_topic_query_embed_dir = os.path.join(\"../\", conf.sent_topic_query_embed_dir)\n",
    "conf.sent_topic_descr_embed_dir = os.path.join(\"../\", conf.sent_topic_descr_embed_dir)\n",
    "\n",
    "metadata_testset, topics_df, topics_df_targets = read_metadata_subset(conf, traintest='test')\n",
    "\n",
    "qs =  topics_df['query'].tolist()\n",
    "ds =  topics_df['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e8105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = '../logs/25m-gru_2022-07-06_07-25-51/output/full_model_weights.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16e83be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[utils] metadata loaded  105360\n",
      "[utils] topics_df_targets loaded for test set 9426\n",
      "[utils] metadata_subset loaded  9426\n"
     ]
    }
   ],
   "source": [
    "# Reading the metadata.\n",
    "metadata_testset, topics_df, topics_df_targets = read_metadata_subset(conf, traintest='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a00c0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MMloader] init from directory  ../../data/yamnet/processed/ train\n",
      "[MMloader] train dataset loaded, length:  4301835\n",
      "[MMloader] init from directory  ../../data/yamnet/processed/ val\n",
      "[MMloader] val dataset loaded, length:  252398\n",
      "[MMloader] init from directory  ../../data/yamnet/processed/ test\n",
      "[MMloader] test dataset loaded, length:  1530873\n",
      "1530752\n"
     ]
    }
   ],
   "source": [
    "# Rename model paths. \n",
    "model_path = Path(model_weights_path).parents[1]\n",
    "model_config_path = os.path.join(model_path, 'config.json')\n",
    "\n",
    "# Opening JSON file\n",
    "f = open(model_config_path)\n",
    "model_config = json.load(f)\n",
    "CFG = from_dict(data_class=Cfg, data=model_config)\n",
    "CFG.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CFG.sp_path = conf.sp_path\n",
    "\n",
    "# Create dataloader of test set.\n",
    "data_loader = MMloader(CFG)\n",
    "\n",
    "# Load the model.\n",
    "full_model = mmModule(CFG)\n",
    "full_model.load_state_dict(torch.load(model_weights_path,  map_location=CFG.device)) \n",
    "full_model = full_model.to(CFG.device)     \n",
    "full_model.eval()\n",
    "\n",
    "# Calculate embeddings for test set.\n",
    "evaluator = Evaluator(CFG, model_path, full_model, data_loader, False)\n",
    "max_samples = evaluator.get_max_data()\n",
    "print(max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e11ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max samples reached\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For now we create a pool of 128*20000 samples\n",
    "max_samples = 128*20000\n",
    "evaluator.encode_testset(max_samples) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c62590",
   "metadata": {},
   "source": [
    "## Return top-k samples from a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746ab25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_topk_fromquery(evaluator, query, k=5):\n",
    "    print(\"Input sentence: \", query)\n",
    "    sent_txt_embed = evaluator.text_to_embed(query)\n",
    "    \n",
    "    # Create similarity matrix\n",
    "    sim = (100.0 * sent_txt_embed @ evaluator.text_encoding.T)\n",
    "    \n",
    "    # return topK\n",
    "    sim = sim.softmax(dim=-1)\n",
    "    values, indices = sim.topk(k)\n",
    "    topk_similar = [evaluator.all_sents[i] for i in indices]\n",
    "    return topk_similar[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a0aed0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  Podcast about dogs.\n",
      "\t I'm going to talk about for dogs.\n",
      "\t I'm obsessed with dogs.\n",
      "\t It just says dogs.\n",
      "\t  Because I love dogs.\n",
      "\t Thank God we both have dogs.\n"
     ]
    }
   ],
   "source": [
    "query = \"Podcast about dogs.\"\n",
    "topk_similar = get_topk_fromquery(evaluator, query, k=5)\n",
    "for sent in topk_similar:\n",
    "    print(\"\\t\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d24315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  People are starving.\n",
      "\t We are starving.\n",
      "\t People are still starving.\n",
      "\t You're not starving.\n",
      "\t I was starving.\n",
      "\t It's starving.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = 'People are starving.'\n",
    "topk_similar = get_topk_fromquery(evaluator, query, k=5)\n",
    "for sent in topk_similar:\n",
    "    print(\"\\t\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ac6018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  That is nice.\n",
      "\t That is nice.\n",
      "\t  I was nice.\n",
      "\t That was nice.\n",
      "\t That was nice.\n",
      "\t That was nice.\n"
     ]
    }
   ],
   "source": [
    "query = 'That is nice.'\n",
    "topk_similar = get_topk_fromquery(evaluator, query, k=5)\n",
    "for sent in topk_similar:\n",
    "    print(\"\\t\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b41b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  Dr. Gerber.\n",
      "\t Dr. Gerber.\n",
      "\t He'd been a carpenter.\n",
      "\t Dr. Pepper.\n",
      "\t Dr. Bacher.\n",
      "\t  It buffer.com.\n"
     ]
    }
   ],
   "source": [
    "query = 'Dr. Gerber.'\n",
    "topk_similar = get_topk_fromquery(evaluator, query, k=5)\n",
    "for sent in topk_similar:\n",
    "    print(\"\\t\", sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a3d88eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t It was therapy.\n",
      "\t I was just going to come a therapist.\n",
      "\t Alternative therapy.\n",
      "\t Welcome to Thrift therapy.\n",
      "\t Physical therapy.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Podcast about therapy.\"\n",
    "topk_similar = get_topk_fromquery(evaluator, query, k=5)\n",
    "for sent in topk_similar:\n",
    "    print(\"\\t\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "68f58ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  Podcast about self-help books.\n",
      "\t I find those self-help books.\n",
      "\t We have enough good self-help stuff.\n",
      "\t We were talking about self-doubt.\n",
      "\t Let's go out self-love.\n",
      "\t I find those self-help books.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Podcast about self-help.\"\n",
    "topk_similar = get_topk_fromquery(evaluator, query, k=5)\n",
    "for sent in topk_similar:\n",
    "    print(\"\\t\", sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04b4d9",
   "metadata": {},
   "source": [
    "### Return top-k from a query (cross modal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef36c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_topk(evaluator, idx, mod='text-text', k=5):\n",
    "    sent = evaluator.all_sents[idx]\n",
    "    print(\"Input sentence: \", sent)\n",
    "    \n",
    "    # Retreive embeddings\n",
    "    sent_txt_embed = evaluator.text_encoding[idx]\n",
    "    sent_audio_embed = evaluator.audio_encoding[idx]\n",
    "    \n",
    "    # Create similarity matrices\n",
    "    if mod=='text-text':\n",
    "        sim = (100.0 * sent_txt_embed @ evaluator.text_encoding.T)\n",
    "    elif mod=='text-audio':\n",
    "        sim = (100.0 * sent_txt_embed @ evaluator.audio_encoding.T)\n",
    "    elif mod=='audio-text':\n",
    "        sim = (100.0 * sent_audio_embed @ evaluator.text_encoding.T)\n",
    "    elif mod=='audio-audio':\n",
    "        sim = (100.0 * sent_audio_embed @ evaluator.audio_encoding.T)\n",
    "    \n",
    "    # return topK\n",
    "    sim = sim.softmax(dim=-1)\n",
    "    values, indices = sim.topk(k)\n",
    "    topk_similar = [evaluator.all_sents[i] for i in indices]\n",
    "    return topk_similar\n",
    "\n",
    "\n",
    "modalities = ['text-text', 'text-audio', 'audio-text', 'audio-audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0a01d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar for id 178989 and modality text-text\n",
      "Input sentence:  It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t It was so strange.\n",
      "prediction: \t That's so strange.\n",
      "prediction: \t That's so strange.\n",
      "\n",
      "Most similar for id 178989 and modality text-audio\n",
      "Input sentence:  It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t That's so strange.\n",
      "prediction: \t He so strange.\n",
      "prediction: \t This is so strange.\n",
      "prediction: \t That's so strange.\n",
      "\n",
      "Most similar for id 178989 and modality audio-text\n",
      "Input sentence:  It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t Strange.\n",
      "prediction: \t It was so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "\n",
      "Most similar for id 178989 and modality audio-audio\n",
      "Input sentence:  It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t It's so strange.\n",
      "prediction: \t That was so strange.\n",
      "prediction: \t He goes.\n",
      "prediction: \t Yes, this is strange.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = random.randint(0, len(evaluator.all_sents))\n",
    "\n",
    "for mod in modalities:\n",
    "    print(\"\\nMost similar for id {} and modality {}\".format(idx, mod))\n",
    "    topk_similar = get_topk(evaluator, idx, mod=mod, k=5)\n",
    "    for sent in topk_similar:\n",
    "        print(\"prediction: \\t\", sent) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1b7fb65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar for id 863328 and modality text-text\n",
      "Input sentence:  What are you most thankful for this Thanksgiving?\n",
      "prediction: \t What are you most thankful for this Thanksgiving?\n",
      "prediction: \t What do you most thankful for for Thanksgiving?\n",
      "prediction: \t What are you plans for this wonderful Thanksgiving.\n",
      "prediction: \t I'm also grateful for sanity.\n",
      "prediction: \t Also intimacy.\n",
      "\n",
      "Most similar for id 863328 and modality text-audio\n",
      "Input sentence:  What are you most thankful for this Thanksgiving?\n",
      "prediction: \t Hey, what are you most thankful for this Thanksgiving.\n",
      "prediction: \t I was think of Thanksgiving.\n",
      "prediction: \t Tell them what you're thankful for.\n",
      "prediction: \t Happy Thanksgiving again.\n",
      "prediction: \t What are you most thankful for this Thanksgiving?\n",
      "\n",
      "Most similar for id 863328 and modality audio-text\n",
      "Input sentence:  What are you most thankful for this Thanksgiving?\n",
      "prediction: \t Let's go hold some heart space together.\n",
      "prediction: \t What are you most thankful for this Thanksgiving?\n",
      "prediction: \t Thanksgiving and Christmas.\n",
      "prediction: \t It comes to Thanksgiving time.\n",
      "prediction: \t Hey, welcome back to family dinner.\n",
      "\n",
      "Most similar for id 863328 and modality audio-audio\n",
      "Input sentence:  What are you most thankful for this Thanksgiving?\n",
      "prediction: \t What do you most thankful for for Thanksgiving?\n",
      "prediction: \t Some people do Christmas Eve.\n",
      "prediction: \t What did you guys do for Thanksgiving?\n",
      "prediction: \t What are you guys favourite biscuits?\n",
      "prediction: \t Tell them what you're thankful for.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = random.randint(0, len(evaluator.all_sents))\n",
    "\n",
    "for mod in modalities:\n",
    "    print(\"\\nMost similar for id {} and modality {}\".format(idx, mod))\n",
    "    topk_similar = get_topk(evaluator, idx, mod=mod, k=5)\n",
    "    for sent in topk_similar:\n",
    "        print(\"prediction: \\t\", sent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8b43c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar for id 846526 and modality text-text\n",
      "Input sentence:  I have a weight-loss goal.\n",
      "prediction: \t I have a weight-loss goal.\n",
      "prediction: \t Those are my goals.\n",
      "prediction: \t It makes or sport.\n",
      "prediction: \t I lost a ton of weight.\n",
      "prediction: \t So that was the score score score.\n",
      "\n",
      "Most similar for id 846526 and modality text-audio\n",
      "Input sentence:  I have a weight-loss goal.\n",
      "prediction: \t That's weight loss.\n",
      "prediction: \t Yeah, what are your next goals?\n",
      "prediction: \t I lost a ton of weight.\n",
      "prediction: \t I have a weight-loss goal.\n",
      "prediction: \t Those are my goals\n",
      "\n",
      "Most similar for id 846526 and modality audio-text\n",
      "Input sentence:  I have a weight-loss goal.\n",
      "prediction: \t Yeah, what are your next goals?\n",
      "prediction: \t What are my personal goals? \n",
      "prediction: \t Let's talk about weight.\n",
      "prediction: \t What about your muscle mass?\n",
      "prediction: \t I have a weight-loss goal\n",
      "\n",
      "Most similar for id 846526 and modality audio-audio\n",
      "Input sentence:  I have a weight-loss goal.\n",
      "prediction: \t I have a weight-loss goal.\n",
      "prediction: \t Those are my goals.\n",
      "prediction: \t What about your muscle mass?\n",
      "prediction: \t I would try and get my body weight.\n",
      "prediction: \t Do you have money goals?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = random.randint(0, len(evaluator.all_sents))\n",
    "\n",
    "for mod in modalities:\n",
    "    print(\"\\nMost similar for id {} and modality {}\".format(idx, mod))\n",
    "    topk_similar = get_topk(evaluator, idx, mod=mod, k=5)\n",
    "    for sent in topk_similar:\n",
    "        print(\"prediction: \\t\", sent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b14811da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar for id 178989 and modality text-text\n",
      "Input sentence:  So I was depressed probably for about five years.\n",
      "prediction: \t So I was depressed probably for about five years.\n",
      "prediction: \t I was the one that was fucking depressed.\n",
      "prediction: \t My son has been drug-free now over five years.\n",
      "prediction: \t But I was desperate.\n",
      "prediction: \t stop struggling.\n",
      "\n",
      "Most similar for id 178989 and modality text-audio\n",
      "Input sentence:  So I was depressed probably for about five years.\n",
      "prediction: \t So I was depressed probably for about five years.\n",
      "prediction: \t So I practice for five years.\n",
      "prediction: \t They're probably psyched as hell.\n",
      "prediction: \t But I was desperate.\n",
      "prediction: \t I'm a very independent person.\n",
      "\n",
      "Most similar for id 178989 and modality audio-text\n",
      "Input sentence:  So I was depressed probably for about five years.\n",
      "prediction: \t So I was depressed probably for about five years.\n",
      "prediction: \t I'm like no I never said I was depressed.\n",
      "prediction: \t I had feelings of depression.\n",
      "prediction: \t stop struggling.\n",
      "prediction: \t I know that I have depression.\n",
      "\n",
      "Most similar for id 178989 and modality audio-audio\n",
      "Input sentence:  So I was depressed probably for about five years.\n",
      "prediction: \t So I was depressed probably for about five years.\n",
      "prediction: \t My heart almost stopped crying.\n",
      "prediction: \t So I'm just there all the time.\n",
      "prediction: \t But I was desperate.\n",
      "prediction: \t I'm like no I never said I was depressed.\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(evaluator.all_sents))\n",
    "\n",
    "for mod in modalities:\n",
    "    print(\"\\nMost similar for id {} and modality {}\".format(idx, mod))\n",
    "    topk_similar = get_topk(evaluator, idx, mod=mod, k=5)\n",
    "    for sent in topk_similar:\n",
    "        print(\"prediction: \\t\", sent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "605506b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar for id 178989 and modality text-text\n",
      "Input sentence:  I don't think I made out with her like at the club.\n",
      "prediction: \t I don't think I made out with her like at the club.\n",
      "prediction: \t They've been more than like amicable.\n",
      "prediction: \t I don't even know how like, I'm an adult\n",
      "prediction: \t Definitely my favorite couple.\n",
      "prediction: \t So yeah, like half a kiss\n",
      "\n",
      "Most similar for id 178989 and modality text-audio\n",
      "Input sentence:  I don't think I made out with her like at the club.\n",
      "prediction: \t I don't think I made out with her like at the club.\n",
      "prediction: \t They've been more than like amicable.\n",
      "prediction: \t No way a couple.\n",
      "prediction: \t Give me a kiss.\n",
      "prediction: \t push Guinness down the toilet.\n",
      "\n",
      "Most similar for id 178989 and modality audio-text\n",
      "Input sentence:  I don't think I made out with her like at the club.\n",
      "prediction: \t I don't think I made out with her like at the club.\n",
      "prediction: \t No way a couple.\n",
      "prediction: \t They've been more than like amicable.\n",
      "prediction: \t Do you think I know who they are?\n",
      "prediction: \t Give me a kiss.\n",
      "\n",
      "Most similar for id 178989 and modality audio-audio\n",
      "Input sentence:  I don't think I made out with her like at the club.\n",
      "prediction: \t I don't think I made out with her like at the club.\n",
      "prediction: \t It was like a moment in like drunk.\n",
      "prediction: \t Don't tell me you went but turkey.\n",
      "prediction: \t They've been more than like amicable.\n",
      "prediction: \t I was he single.\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(evaluator.all_sents))\n",
    "\n",
    "for mod in modalities:\n",
    "    print(\"\\nMost similar for id {} and modality {}\".format(idx, mod))\n",
    "    topk_similar = get_topk(evaluator, idx, mod=mod, k=5)\n",
    "    for sent in topk_similar:\n",
    "        print(\"prediction: \\t\", sent)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bea10b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar for id 470482 and modality text-text\n",
      "Input sentence:  Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "\n",
      "Most similar for id 470482 and modality text-audio\n",
      "Input sentence:  Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "\n",
      "Most similar for id 470482 and modality audio-text\n",
      "Input sentence:  Anchor will distribute your podcast for you.\n",
      "prediction: \t GE will distribute your podcast for you.\n",
      "prediction: \t  They will distribute your podcast for you.\n",
      "prediction: \t  Also distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "\n",
      "Most similar for id 470482 and modality audio-audio\n",
      "Input sentence:  Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t And can you share a little bit of your job history?\n",
      "prediction: \t Anchor will distribute your podcast for you.\n",
      "prediction: \t Anchor will distribute your podcast for you.\n"
     ]
    }
   ],
   "source": [
    "idx = 470482\n",
    "for mod in modalities:\n",
    "    print(\"\\nMost similar for id {} and modality {}\".format(idx, mod))\n",
    "    topk_similar = get_topk(evaluator, idx, mod=mod, k=5)\n",
    "    for sent in topk_similar:\n",
    "        print(\"prediction: \\t\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce20c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:contrastivePodcast] *",
   "language": "python",
   "name": "conda-env-contrastivePodcast-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
